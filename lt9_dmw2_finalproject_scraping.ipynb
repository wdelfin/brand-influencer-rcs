{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "388f51d3",
   "metadata": {},
   "source": [
    "# Birds of a Feather Flock Together: A Recommender System for Brand-Influencer Matching\n",
    "\n",
    "**MSDS 2023 Term 3 LT9** | Albao, Delfin, Lazaro, Lucas, Menorca\n",
    "\n",
    "This notebook serves as a supplementary to the main report on the details of the data scraping done for this project.\n",
    "\n",
    "In this project, the users followed by an account is considered as its social network. Moving forward, \"following\" and \"social network\" may be used interchangeably.\n",
    "\n",
    "**Data Source**\n",
    "\n",
    "All of the datasets used in this project was gathered via Twitter API. It includes the profile of Twitter users, their tweets, and their social network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cd27ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-13T10:24:56.747468Z",
     "start_time": "2023-03-13T10:24:56.057610Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from getpass import getpass\n",
    "from sqlalchemy import create_engine\n",
    "import sqlite3\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b92786",
   "metadata": {},
   "source": [
    "# I. Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce8d999",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-13T10:24:56.801370Z",
     "start_time": "2023-03-13T10:24:56.750124Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the database in which the collected data will be stored\n",
    "sqlite_db = 'dmw2_final_project.db'\n",
    "sqlite_conn = f'sqlite:///{sqlite_db}'\n",
    "engine = create_engine(f'sqlite:///{sqlite_db}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19673bb9",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-13T10:24:55.071Z"
    }
   },
   "outputs": [],
   "source": [
    "# Input the bearer token of your Twitter Dev Account to be able to scrape\n",
    "bearer_token = getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1018b9bf",
   "metadata": {},
   "source": [
    "## II. The Brand's Profile: *Dove*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8b4c81",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-13T10:24:55.075Z"
    }
   },
   "outputs": [],
   "source": [
    "# Input the brand's Twitter username\n",
    "brand_username = 'Dove_PH'\n",
    "try:\n",
    "    response = (requests\n",
    "                    .get(f'https://api.twitter.com/2/users/by/username/{brand_username}',\n",
    "                         headers={'Authorization': f'Bearer {bearer_token}'},\n",
    "                         params={\"user.fields\": \"id,created_at,description,\" \\\n",
    "                                 \"location,name,username,url,verified,\" \\\n",
    "                                 \"public_metrics\"})\n",
    "                    .json()\n",
    "                    )\n",
    "except:\n",
    "    print(\"Invalid request: check username input or bearer_token\")\n",
    "\n",
    "# Store the information into a pandas dataframe\n",
    "brand_info = response.get('data')\n",
    "df_brand = pd.DataFrame([brand_info])\n",
    "df_brand = (df_brand.drop('public_metrics', axis=1)\n",
    "                    .join(pd.json_normalize(df_brand.public_metrics)))\n",
    "\n",
    "# # Save the information into the sqlite db\n",
    "# tbl_brand = 'brands'\n",
    "# df_brand.to_sql(tbl_brand, sqlite_conn, index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9daaea",
   "metadata": {},
   "source": [
    "# III. Social Network of Dove\n",
    "\n",
    "*Dove*'s social network was used as a reference on what characteristics does *Dove* look for in an influencer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972ae4df",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-13T10:24:55.081Z"
    }
   },
   "outputs": [],
   "source": [
    "# Endpoint for getting the users that follow a given ID\n",
    "url = f'https://api.twitter.com/2/users/{brand_id}/following'\n",
    "\n",
    "# Set the parameters\n",
    "params = {'max_results': 1000,\n",
    "          'user.fields': 'id,username,created_at,location,description,' \\\n",
    "                         'public_metrics,url,name,protected'}\n",
    "headers = {'Authorization': f'Bearer {bearer_token}'}\n",
    "\n",
    "following_ids = []\n",
    "start = time.time()\n",
    "page = 1\n",
    "\n",
    "# Loop through all of the pages to get all the following\n",
    "while True:\n",
    "    if page == 1:\n",
    "        print(f\"At page {page}\")\n",
    "    elif page % 2 == 0:\n",
    "        print(f\"At page {page}\")\n",
    "                \n",
    "    r = requests.get(url, headers=headers, params=params).json()\n",
    "    following_ids.extend(r['data'])\n",
    "\n",
    "    if 'next_token' in r['meta']:\n",
    "        params.update({'pagination_token': r['meta']['next_token']})\n",
    "    else:\n",
    "        break\n",
    "    page += 1\n",
    "    time.sleep(1)\n",
    "\n",
    "end_time = time.time() - start\n",
    "print(f\"Total scrape time is {end_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f39845",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-13T10:24:55.085Z"
    }
   },
   "outputs": [],
   "source": [
    "# Store the collected data into a pandas dataframe\n",
    "df_following = pd.DataFrame(following_ids)\n",
    "df_following = (df_following.drop('public_metrics', axis=1)\n",
    "                            .join(pd.json_normalize(df_following.public_metrics)))\n",
    "\n",
    "# Defining an influencer as those with at least 50K followers\n",
    "valid_following_ids = (df_following.loc[(df_following.followers_count >= 50000)\n",
    "                                       & ~(df_following.username.str.contains('Dove'))]\n",
    "                                           .id.unique().tolist())\n",
    "df_following.loc[df_following.loc[df_following.id.isin(valid_following_ids)].index, 'included'] = 1\n",
    "df_following.included.fillna(0, inplace=True)\n",
    "\n",
    "# Save the scraped info into the sqlite db\n",
    "tbl_following = 'following'\n",
    "df_following.to_sql(tbl_following, con=sqlite_conn, index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62985b4",
   "metadata": {},
   "source": [
    "# III. Influencers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ae54d8",
   "metadata": {},
   "source": [
    "## Reference Influencer 1: *Anne Curtis*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a145b43",
   "metadata": {},
   "source": [
    "### Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e94484",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-13T10:24:55.092Z"
    }
   },
   "outputs": [],
   "source": [
    "# Input the influencers' Twitter username\n",
    "ref_influencer_username = 'annecurtissmith'\n",
    "try:\n",
    "    response = (requests\n",
    "                    .get(f'https://api.twitter.com/2/users/by/username/{ref_influencer_username}',\n",
    "                         headers={'Authorization': f'Bearer {bearer_token}'},\n",
    "                         params={\"user.fields\": \"id,created_at,description,\" \\\n",
    "                                 \"location,name,username,url,verified,\" \\\n",
    "                                 \"public_metrics\"})\n",
    "                    .json()\n",
    "                    )\n",
    "except:\n",
    "    print(\"Invalid request: check username input or bearer_token\")\n",
    "\n",
    "# Store info into a pandas dataframe\n",
    "ref_influencer_info = response.get('data')\n",
    "ref_influencer_id = ref_influencer_info['id']\n",
    "\n",
    "df_ref_influencers = pd.DataFrame([ref_influencer_info])\n",
    "df_ref_influencers = (df_ref_influencers.drop(['public_metrics'], axis=1)\n",
    "                                        .join(pd.json_normalize(df_ref_influencers.public_metrics)))\n",
    "\n",
    "# Save the dataframe into the sqlite db\n",
    "tbl_ref_inf = 'ref_influencers'\n",
    "df_ref_influencers.to_sql(tbl_ref_inf, sqlite_conn, index=False, if_exists='append')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de512ba0",
   "metadata": {},
   "source": [
    "### Social Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be184f2f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-13T10:24:55.097Z"
    }
   },
   "outputs": [],
   "source": [
    "# Anne following\n",
    "url = f'https://api.twitter.com/2/users/{ref_influencer_id}/following'\n",
    "\n",
    "params = {'max_results': 1000,\n",
    "          'user.fields': 'id,username,created_at,location,description,' \\\n",
    "                         'public_metrics,url,name,protected'}\n",
    "headers = {'Authorization': f'Bearer {bearer_token}'}\n",
    "\n",
    "inf_following_ids = []\n",
    "\n",
    "start = time.time()\n",
    "page = 1\n",
    "\n",
    "while True:\n",
    "    if page == 1:\n",
    "        print(f\"At page {page}\")\n",
    "    elif page % 2 == 0:\n",
    "        print(f\"At page {page}\")\n",
    "                \n",
    "    r = requests.get(url, headers=headers, params=params).json()\n",
    "    inf_following_ids.extend(r['data'])\n",
    "    time.sleep(2)\n",
    "\n",
    "    if 'next_token' in r['meta']:\n",
    "        params.update({'pagination_token': r['meta']['next_token']})\n",
    "    else:\n",
    "        break\n",
    "    page += 1\n",
    "    \n",
    "end_time = time.time() - start\n",
    "print(f\"Total scrape time is {end_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38480df",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-13T10:24:55.102Z"
    }
   },
   "outputs": [],
   "source": [
    "# Store into a pandas dataframe\n",
    "df_ref_following = pd.DataFrame(inf_following_ids)\n",
    "df_ref_following = (df_ref_following.drop(['public_metrics', 'withheld'], axis=1)\n",
    "                    .join(pd.json_normalize(df_ref_following.public_metrics)))\n",
    "\n",
    "# Save into the sqlite db\n",
    "tbl_influencers = 'influencers'\n",
    "df_ref_following.to_sql(tbl_influencers, engine,\n",
    "                            index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779a90f9",
   "metadata": {},
   "source": [
    "## Reference Influencer 2: *Alden Richards*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e9d4b9",
   "metadata": {},
   "source": [
    "### Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449c0a88",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-13T10:24:55.107Z"
    }
   },
   "outputs": [],
   "source": [
    "# Input influencers' Twitter username\n",
    "ref_influencer_username = 'aldenrichards02'\n",
    "try:\n",
    "    response = (requests\n",
    "                    .get(f'https://api.twitter.com/2/users/by/username/{ref_influencer_username}',\n",
    "                         headers={'Authorization': f'Bearer {bearer_token}'},\n",
    "                         params={\"user.fields\": \"id,created_at,description,\" \\\n",
    "                                 \"location,name,username,url,verified,\" \\\n",
    "                                 \"public_metrics\"})\n",
    "                    .json()\n",
    "                    )\n",
    "except:\n",
    "    print(\"Invalid request: check username input or bearer_token\")\n",
    "\n",
    "# Store data into pandas dataframe\n",
    "ref_influencer_info = response.get('data')\n",
    "ref_influencer_id = ref_influencer_info['id']\n",
    "\n",
    "df_ref_influencers = pd.DataFrame([ref_influencer_info])\n",
    "df_ref_influencers = (df_ref_influencers.drop(['public_metrics'], axis=1)\n",
    "                                        .join(pd.json_normalize(df_ref_influencers.public_metrics)))\n",
    "df_ref_influencers.head()\n",
    "\n",
    "# Save into sqlite db\n",
    "tbl_ref_inf = 'ref_influencers'\n",
    "df_ref_influencers.to_sql(tbl_ref_inf, sqlite_conn, index=False, if_exists='append')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ea58aa",
   "metadata": {},
   "source": [
    "### Social Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a88fd2",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-13T10:24:55.112Z"
    }
   },
   "outputs": [],
   "source": [
    "# Alden following\n",
    "url = f'https://api.twitter.com/2/users/{ref_influencer_id}/following'\n",
    "\n",
    "params = {'max_results': 1000,\n",
    "          'user.fields': 'id,username,created_at,location,description,' \\\n",
    "                         'public_metrics,url,name,protected'}\n",
    "headers = {'Authorization': f'Bearer {bearer_token}'}\n",
    "\n",
    "inf_following_ids = []\n",
    "\n",
    "start = time.time()\n",
    "page = 1\n",
    "\n",
    "while True:\n",
    "    if page == 1:\n",
    "        print(f\"At page {page}\")\n",
    "    elif page % 2 == 0:\n",
    "        print(f\"At page {page}\")\n",
    "                \n",
    "    r = requests.get(url, headers=headers, params=params).json()\n",
    "    inf_following_ids.extend(r['data'])\n",
    "    time.sleep(2)\n",
    "\n",
    "    if 'next_token' in r['meta']:\n",
    "        params.update({'pagination_token': r['meta']['next_token']})\n",
    "    else:\n",
    "        break\n",
    "    page += 1\n",
    "    \n",
    "end_time = time.time() - start\n",
    "print(f\"Total scrape time is {end_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24baea5",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-13T10:24:55.116Z"
    }
   },
   "outputs": [],
   "source": [
    "# Store info in pandas dataframe\n",
    "df_ref_following = pd.DataFrame(inf_following_ids)\n",
    "df_ref_following = (df_ref_following.drop(['public_metrics'], axis=1)\n",
    "                    .join(pd.json_normalize(df_ref_following.public_metrics)))\n",
    "\n",
    "# Save dataframe in sqlite db\n",
    "tbl_influencers = 'influencers'\n",
    "df_ref_following.to_sql(tbl_influencers, engine,\n",
    "                            index=False, if_exists='append')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04698fd",
   "metadata": {},
   "source": [
    "# IV. Influencer Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5391c910",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-13T10:24:55.121Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ensure that the influencer profiles are unique, then save into the Partners table\n",
    "tbl_influencers = 'influencers'\n",
    "df_influencers = pd.read_sql(f\"SELECT * FROM {tbl_influencers}\", sqlite_conn)\n",
    "df_influencers.drop_duplicates('id', keep='first', inplace=True)\n",
    "\n",
    "tbl_partners = 'partners'\n",
    "df_influencers.to_sql(tbl_partners, engine, index=False, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282d8bbf",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-13T10:24:55.125Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the partners table to get the unique partner IDs\n",
    "tbl_partners = 'partners'\n",
    "df_partners = pd.read_sql(f\"SELECT * FROM {tbl_partners}\", sqlite_conn)\n",
    "\n",
    "# Scrape the partners' tweets\n",
    "headers = {'Authorization': f'Bearer {bearer_token}'}\n",
    "partner_tweets = []\n",
    "start = time.time()\n",
    "\n",
    "for idx, partner_id in enumerate(df_partners.id.unique().tolist()):\n",
    "    \n",
    "    print(f'Partner: {idx}')\n",
    "    params = {'max_results': 100,\n",
    "              'exclude': 'retweets',\n",
    "              'place.fields': 'country,country_code,full_name,place_type',\n",
    "              'tweet.fields': 'id,created_at,text,lang,' \\\n",
    "                              'conversation_id,in_reply_to_user_id,author_id,' \\\n",
    "                              'public_metrics,possibly_sensitive',\n",
    "              'user.fields': 'id'}\n",
    "    url = f'https://api.twitter.com/2/users/{partner_id}/tweets'\n",
    "    \n",
    "    r = requests.get(url, headers=headers, params=params).json()\n",
    "    time.sleep(1.5)\n",
    "    \n",
    "    try:\n",
    "        if r['meta']['result_count'] > 0:\n",
    "            partner_tweets.extend(r['data'])\n",
    "            if 'next_token' in r['meta']:\n",
    "                print('Next page exists')\n",
    "            else:\n",
    "                print(f'No next token')\n",
    "        else:\n",
    "            print(f'Result = 0: {r}')\n",
    "\n",
    "    except KeyError:\n",
    "        if r['errors'][0]['title'] == 'Authorization Error':\n",
    "            print(f'Authorization Error: {r}')\n",
    "        else:\n",
    "            print(f'Error encountered: {r}')\n",
    "                   \n",
    "end_time = time.time() - start\n",
    "print(f\"Total scrape time is {end_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c677e8",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-13T10:24:55.129Z"
    }
   },
   "outputs": [],
   "source": [
    "# Store info into pandas dataframe\n",
    "df_partner_tweets = pd.DataFrame(partner_tweets)\n",
    "df_partner_tweets = (df_partner_tweets.drop(['public_metrics', 'withheld',\n",
    "                                             'edit_history_tweet_ids'], axis=1)\n",
    "                          .join(pd.json_normalize(df_partner_tweets.public_metrics)))\n",
    "\n",
    "# Save dataframe into sqlite db\n",
    "tbl_partner_tweets = 'partner_tweets'\n",
    "df_partner_tweets.to_sql(tbl_partner_tweets, sqlite_conn,\n",
    "                            index=False, if_exists='replace')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "175.818px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
